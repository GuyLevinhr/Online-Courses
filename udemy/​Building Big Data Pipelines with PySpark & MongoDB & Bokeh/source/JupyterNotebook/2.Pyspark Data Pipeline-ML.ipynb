{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure Spark\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .master('local[2]')\\\n",
    "            .appName('quake_etl_ml')\\\n",
    "            .config('spark.jars.packages','org.mongodb.spark:mongo-spark-connector_2.12:2.4.1')\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(time='2017-01-02T00:13:06.300Z', latitude='-36.0365', longitude='51.9288', depth='10', mag='5.7', magType='mwb', nst=None, gap='26', dmin='14.685', rms='1.37', net='us', id='us10007p5d', updated='2017-03-27T23:53:17.040Z', place='Southwest Indian Ridge', type='earthquake', horizontalError='10.3', depthError='1.7', magError='0.068', magNst='21', status='reviewed', locationSource='us', magSource='us')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ML\n",
    "#Data Pre-processing\n",
    "\n",
    "#Load the test data file into DF\n",
    "\n",
    "df_test = spark.read.csv(r'query.csv',header=True)\n",
    "\n",
    "#preview\n",
    "df_test.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------+--------+---------+---------+--------------+----------+----+--------------------+\n",
      "|      Date|Depth|          ID|Latitude|Longitude|Magnitude|Magnitude Type|      Type|Year|                 _id|\n",
      "+----------+-----+------------+--------+---------+---------+--------------+----------+----+--------------------+\n",
      "|01/02/1965|131.6|ISCGEM860706|  19.246|  145.616|      6.0|            MW|Earthquake|1965|[6001d3cd4f44ba5b...|\n",
      "|01/04/1965| 80.0|ISCGEM860737|   1.863|  127.352|      5.8|            MW|Earthquake|1965|[6001d3cd4f44ba5b...|\n",
      "|01/05/1965| 20.0|ISCGEM860762| -20.579| -173.972|      6.2|            MW|Earthquake|1965|[6001d3cd4f44ba5b...|\n",
      "|01/08/1965| 15.0|ISCGEM860856| -59.076|  -23.557|      5.8|            MW|Earthquake|1965|[6001d3cd4f44ba5b...|\n",
      "|01/09/1965| 15.0|ISCGEM860890|  11.938|  126.427|      5.8|            MW|Earthquake|1965|[6001d3cd4f44ba5b...|\n",
      "+----------+-----+------------+--------+---------+---------+--------------+----------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the training data from mongo into DF\n",
    "df_train = spark.read.format('mongo')\\\n",
    "    .option('spark.mongodb.input.uri','mongodb://127.0.0.1:27017/Quake.quakes').load()\n",
    "\n",
    "#preview\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+---------+------+\n",
      "|                date|Latitude|Longitude|Magnitude| Depth|\n",
      "+--------------------+--------+---------+---------+------+\n",
      "|2017-01-02T00:13:...|-36.0365|  51.9288|      5.7|    10|\n",
      "|2017-01-02T13:13:...|  -4.895| -76.3675|      5.9|   106|\n",
      "|2017-01-02T13:14:...|-23.2513| 179.2383|      6.3|551.62|\n",
      "|2017-01-03T09:09:...| 24.0151|  92.0177|      5.7|    32|\n",
      "|2017-01-03T21:19:...|-43.3527| -74.5017|      5.5| 10.26|\n",
      "+--------------------+--------+---------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select column to thet we need\n",
    "df_test_clean = df_test['time','Latitude','Longitude','mag','Depth']\n",
    "\n",
    "#Rename columns\n",
    "df_test_clean = df_test_clean.withColumnRenamed('time','date')\\\n",
    "                            .withColumnRenamed('mag','Magnitude')\n",
    "\n",
    "#preview\n",
    "df_test_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Magnitude: string (nullable = true)\n",
      " |-- Depth: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Magnitude: double (nullable = true)\n",
      " |-- Depth: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print df_test_clean schema\n",
    "df_test_clean.printSchema()\n",
    "\n",
    "# cost fileds from string to numeric types\n",
    "df_test_clean = df_test_clean.withColumn('Latitude',df_test_clean['Latitude'].cast(DoubleType()))\\\n",
    "                .withColumn('Longitude',df_test_clean['Longitude'].cast(DoubleType()))\\\n",
    "                .withColumn('Depth',df_test_clean['Depth'].cast(DoubleType()))\\\n",
    "                .withColumn('Magnitude',df_test_clean['Magnitude'].cast(DoubleType()))\n",
    "\n",
    "#Print df_test_clean schema after change types\n",
    "df_test_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and testing df\n",
    "df_testing = df_test_clean['Latitude','Longitude','Magnitude','Depth']\n",
    "df_training = df_train['Latitude','Longitude','Magnitude','Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop nulls\n",
    "df_testing = df_testing.dropna()\n",
    "df_training = df_training.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build ML model\n",
    "\n",
    "# select features to parse into our modek then create the feature vector\n",
    "assembler = VectorAssembler(inputCols=['Latitude','Longitude','Depth'],outputCol='features')\n",
    "\n",
    "#create the model\n",
    "model_reg = RandomForestRegressor(featuresCol='features',labelCol='Magnitude')\n",
    "\n",
    "# Chain the assemblier with the model in a pipeline\n",
    "pipeline = Pipeline(stages=[assembler,model_reg])\n",
    "\n",
    "# Train model\n",
    "model = pipeline.fit(df_training)\n",
    "\n",
    "# Make the prediction\n",
    "pred_resulte = model.transform(df_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+------+--------------------+------------------+\n",
      "|Latitude|Longitude|Magnitude| Depth|            features|        prediction|\n",
      "+--------+---------+---------+------+--------------------+------------------+\n",
      "|-36.0365|  51.9288|      5.7|  10.0|[-36.0365,51.9288...| 5.833306409270847|\n",
      "|  -4.895| -76.3675|      5.9| 106.0|[-4.895,-76.3675,...| 5.877663364698073|\n",
      "|-23.2513| 179.2383|      6.3|551.62|[-23.2513,179.238...| 5.918379334619855|\n",
      "| 24.0151|  92.0177|      5.7|  32.0|[24.0151,92.0177,...|5.8978373572569085|\n",
      "|-43.3527| -74.5017|      5.5| 10.26|[-43.3527,-74.501...| 5.872559885848837|\n",
      "+--------+---------+---------+------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preview pred_resulte df\n",
    "pred_resulte.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared Error(RMSE) on test data = 0.401871\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "# rmse should be less than 0.5 for model to be useful\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='Magnitude',predictionCol='prediction',metricName='rmse')\n",
    "rmse = evaluator.evaluate(pred_resulte)\n",
    "print('Root mean squared Error(RMSE) on test data = %g' %rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------------------+----+------------------+\n",
      "|Latitude|Longitude|    Pred_Magnitude|Year|              rmse|\n",
      "+--------+---------+------------------+----+------------------+\n",
      "|-36.0365|  51.9288| 5.833306409270847|2017|0.4018710001835658|\n",
      "|  -4.895| -76.3675| 5.877663364698073|2017|0.4018710001835658|\n",
      "|-23.2513| 179.2383| 5.918379334619855|2017|0.4018710001835658|\n",
      "| 24.0151|  92.0177|5.8978373572569085|2017|0.4018710001835658|\n",
      "|-43.3527| -74.5017| 5.872559885848837|2017|0.4018710001835658|\n",
      "|-19.3733| 176.0518| 5.966636348806326|2017|0.4018710001835658|\n",
      "|-19.3977| 175.9532| 5.884481024542788|2017|0.4018710001835658|\n",
      "|-19.1207| 176.1875| 5.884481024542788|2017|0.4018710001835658|\n",
      "|-18.9749| 176.2872| 5.964495990390334|2017|0.4018710001835658|\n",
      "|-17.8694| 167.1235| 6.005895726135375|2017|0.4018710001835658|\n",
      "|-18.7942| 176.2567| 5.889364924849649|2017|0.4018710001835658|\n",
      "|-22.3176|  -67.795|  5.89005740404204|2017|0.4018710001835658|\n",
      "| -6.2269| 147.4769| 5.858057952384796|2017|0.4018710001835658|\n",
      "| -54.327|-135.8585|5.7924736636382015|2017|0.4018710001835658|\n",
      "| 74.3859| -92.4156| 5.937327867212472|2017|0.4018710001835658|\n",
      "|  4.4782| 122.6171| 5.961727212964164|2017|0.4018710001835658|\n",
      "| 14.6898|   144.34| 5.890156975481402|2017|0.4018710001835658|\n",
      "|-10.1132| 161.0271| 5.992937381618928|2017|0.4018710001835658|\n",
      "| -22.821| -69.8033| 5.862887598905414|2017|0.4018710001835658|\n",
      "|  -20.16|  46.6469| 5.853862964998572|2017|0.4018710001835658|\n",
      "+--------+---------+------------------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#craete the prediction dataset\n",
    "df_pred_resulte = pred_resulte['Latitude','Longitude','prediction']\n",
    "\n",
    "df_pred_resulte = df_pred_resulte.withColumnRenamed('prediction','Pred_Magnitude')\n",
    "\n",
    "#Add columns to pred dataset\n",
    "df_pred_resulte = df_pred_resulte.withColumn('Year',lit('2017'))\\\n",
    "                    .withColumn('rmse',lit(rmse))\n",
    "\n",
    "#priview\n",
    "df_pred_resulte.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the predictiob dataset into mongodb\n",
    "df_pred_resulte.write.format('mongo')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('spark.mongodb.output.uri','mongodb://127.0.0.1:27017/Quake.pred_results').save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
